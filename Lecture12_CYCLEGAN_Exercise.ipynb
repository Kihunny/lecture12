{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import itertools\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import ImageDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        #make residual block with nn.ReflectionPad2d, nn.Conv2d, nn.InstanceNorm2d, nn.ReLU\n",
    "        conv_block = [    ]\n",
    "       \n",
    "        self.conv_block = nn.Sequential(*conv_block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.conv_block(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_nc, output_nc, n_residual_blocks=9):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        # Initial convolution block \n",
    "        # Conv nn.Reflectionpad2d , nn.Conv2d, nn.InstanceNorm2d , nn.ReLU\n",
    "        model = [    ]\n",
    "\n",
    "        # Downsampling\n",
    "        in_features = 64\n",
    "        out_features = in_features*2\n",
    "        \n",
    "        # make 3 downsampling with for\n",
    "        # make Conv2d with stride 2 / InstanceNorm2d , nn.ReLU\n",
    "        for _ in range(2):\n",
    "            model += [   ]\n",
    "            in_features = out_features\n",
    "            out_features = in_features*2\n",
    "\n",
    "        # Make Residual blocks with class ResidualBlock\n",
    "        for _ in range(n_residual_blocks):\n",
    "            model += []\n",
    "\n",
    "        # Upsampling\n",
    "        # make ConvTranspose2d with stride 2 / InstanceNorm2d , nn.ReLU\n",
    "        out_features = in_features//2\n",
    "        for _ in range(2):\n",
    "            model += [   ]\n",
    "            in_features = \n",
    "            out_features = \n",
    "\n",
    "        # Output layer\n",
    "        # make Reflectionpad2d, Conv2d, Tanh\n",
    "        model += [   ]\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_nc):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        # A bunch of convolutions one after another\n",
    "        \n",
    "        # conv2d kernel_size = 4 stride=2 padding =1 , LeakyReLU \n",
    "        model = [    ]\n",
    "\n",
    "        # conv2d kernel_size = 4 stride=2 padding =1 , InstanceNorm2d, LeakyRelu\n",
    "        model += [   ]\n",
    "\n",
    "        # conv2d kernel_size = 4 stride=2 padding =1 , InstanceNorm2d, LeakyRelu\n",
    "        model += [  ]\n",
    "        # conv2d kernel_size = 4 padding=1 , InstanceNorm2d, LeakyRelu\n",
    "        model += [  ) ]\n",
    "\n",
    "        # FCN classification layer\n",
    "        model += []\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x =  self.model(x)\n",
    "        # Average pooling and flatten\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Definition of variables ######\n",
    "input_nc = 3\n",
    "output_nc = 3\n",
    "size = 256\n",
    "device = torch.device(\"cuda\")\n",
    "batch_size = 32\n",
    "lr = 0.001\n",
    "\n",
    "# Networks 2 Generator / 2 Discriminator\n",
    "netG_A2B = \n",
    "netG_B2A = \n",
    "netD_A = \n",
    "netD_B = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to device\n",
    "\n",
    "\n",
    "# criterion MSE and L1Loss\n",
    "\n",
    "\n",
    "# Optimizers of 4 models with lr\n",
    "\n",
    "\n",
    "# intermidiate Tensor\n",
    "Tensor = torch.cuda.FloatTensor\n",
    "input_A = Tensor(batch_size,input_nc,size,size)\n",
    "input_B = Tensor(batch_size,input_nc,size,size)\n",
    "target_real = Tensor(batch_size).fill_(1.0)\n",
    "target_fake = Tensor(batch_size).fill_(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform and Dataset loader\n",
    "transforms_ = [ transforms.Resize(int(size*1.12), Image.BICUBIC), \n",
    "                transforms.RandomCrop(size), \n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)) ]\n",
    "dataloader = DataLoader(ImageDataset('datasets/apple2orange', transforms_=transforms_, unaligned=False), \n",
    "                        batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, 200):\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        # Set model input\n",
    "        real_A = (input_A.copy_(batch['A']))\n",
    "        real_B = (input_B.copy_(batch['B']))\n",
    "\n",
    "        ###### Generators A2B and B2A ######\n",
    "        #zero grad\n",
    "        \n",
    "\n",
    "        # GAN loss\n",
    "        #make fake_B and Discriminate\n",
    "        fake_B = \n",
    "        pred_fake = \n",
    "        loss_GAN_A2B = \n",
    "\n",
    "        #make fake A and Discriminate\n",
    "        fake_A = \n",
    "        pred_fake = \n",
    "        loss_GAN_B2A = \n",
    "\n",
    "        # Calculate Cycle loss\n",
    "        recovered_A = \n",
    "        loss_cycle_ABA = \n",
    "\n",
    "        recovered_B = \n",
    "        loss_cycle_BAB = \n",
    "\n",
    "        # Total loss\n",
    "        loss_G =  loss_GAN_A2B + loss_GAN_B2A + loss_cycle_ABA + loss_cycle_BAB\n",
    "        loss_G.backward()\n",
    "        \n",
    "        optimizer_G.step()\n",
    "        ###################################\n",
    "\n",
    "        ###### Discriminator A ######\n",
    "        optimizer_D_A.zero_grad()\n",
    "\n",
    "        # Real loss\n",
    "        pred_real = \n",
    "        loss_D_real =\n",
    "\n",
    "        # Fake loss\n",
    "        pred_fake = \n",
    "        loss_D_fake = \n",
    "\n",
    "        # Total loss\n",
    "        loss_D_A = (loss_D_real + loss_D_fake)*0.5\n",
    "        loss_D_A.backward()\n",
    "\n",
    "        optimizer_D_A.step()\n",
    "        ###################################\n",
    "\n",
    "        ###### Discriminator B ######\n",
    "        optimizer_D_B.zero_grad()\n",
    "\n",
    "        # Real loss\n",
    "        pred_real = \n",
    "        loss_D_real = \n",
    "        \n",
    "        # Fake loss\n",
    "        pred_fake =\n",
    "        loss_D_fake = \n",
    "\n",
    "        # Total loss\n",
    "        loss_D_B = (loss_D_real + loss_D_fake)*0.5\n",
    "        loss_D_B.backward()\n",
    "\n",
    "        optimizer_D_B.step()\n",
    "        ###################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
